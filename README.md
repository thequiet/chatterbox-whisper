# Chatterbox Whisper - Production TTS & Speech Processing

A powerful AI application combining **ChatterboxTTS** (Production-grade Text-to-Speech), **ChatterboxVC** (Voice Conversion), and **Faster-Whisper** (Speech-to-Text) with both FastAPI and Gradio interfaces.

## üåü Features

### üó£Ô∏è ChatterboxTTS (Production TTS)
- **High-quality neural TTS** with natural voice generation
- **Voice cloning** from reference audio samples
- **Advanced controls**: temperature, exaggeration, CFG weights
- **Multiple sampling methods**: min_p, top_p, repetition penalty
- **Reproducible generation** with seed control

### üîÑ ChatterboxVC (Voice Conversion)
- **Real-time voice conversion** between different speakers
- **Target voice customization** using reference audio
- **High-fidelity audio processing**

### üéß Faster-Whisper (Speech-to-Text)
- **Fast and accurate** speech transcription
- **Multiple audio format support**
- **Multilingual capabilities**

### üåê Dual Interface
- **FastAPI**: RESTful API for programmatic access
- **Gradio**: Interactive web interface for easy testing

## üöÄ Quick Start

### Using Docker (Recommended)

```bash
# Build the container
docker build -t chatterbox-whisper .

# Run with GPU support (recommended)
docker run --rm --gpus all -p 7860:7860 -p 7861:7861 chatterbox-whisper

# Or run CPU-only
docker run --rm -p 7860:7860 -p 7861:7861 chatterbox-whisper
```

### Access the Applications
- **FastAPI Documentation**: http://localhost:7860/docs
- **Gradio Interface**: http://localhost:7861
- **Health Check**: http://localhost:7860/health

### RunPod Serverless Deployment

This Docker image is also compatible with **RunPod serverless** for scalable AI inference:

```bash
# For RunPod, use the handler mode
docker run --gpus all -e RUNPOD_MODE=1 your-username/chatterbox-whisper:latest python /handler.py
```

**RunPod Setup:**
1. Push your built image to Docker Hub
2. Create a new template in RunPod Console
3. Use your Docker image: `your-username/chatterbox-whisper:latest`
4. Set container disk to 15GB+ 
5. Enable GPU for optimal performance

The included handler supports:
- **Text-to-Speech** with voice cloning
- **Voice Conversion** between speakers
- **Speech-to-Text** transcription

API calls follow RunPod's standard format with tasks: `tts`, `vc`, `stt`.

## üìã Requirements

### System Requirements
- **Python 3.11** (for best compatibility)
- **CUDA 12.1+** (for GPU acceleration, optional)
- **4GB+ RAM** (8GB+ recommended)
- **2GB+ disk space**

### Core Dependencies
```
chatterbox-tts      # Production TTS system
faster-whisper     # Speech-to-text
torch              # PyTorch with CUDA support
torchaudio         # Audio processing
gradio             # Web interface
fastapi            # REST API
```

## üéÆ Usage Examples

### 1. Basic Text-to-Speech
```python
from chatterbox.tts import ChatterboxTTS

# Initialize model
model = ChatterboxTTS.from_pretrained("cuda")

# Generate speech
wav = model.generate(
    "Hello, this is ChatterboxTTS speaking!",
    temperature=0.8,
    exaggeration=0.5
)
```

### 2. Voice Cloning
```python
# Clone voice from reference audio
wav = model.generate(
    "This text will be spoken in the cloned voice.",
    audio_prompt_path="reference_voice.wav",
    temperature=0.8
)
```

### 3. Voice Conversion
```python
from chatterbox.vc import ChatterboxVC

# Initialize voice conversion
vc_model = ChatterboxVC.from_pretrained("cuda")

# Convert voice
converted_wav = vc_model.generate(
    input_audio="input.wav",
    target_voice_path="target_voice.wav"
)
```

### 4. REST API Usage
```bash
# Transcribe audio
curl -X POST "http://localhost:7860/transcribe" \
     -F "file=@audio.wav"

# Synthesize text
curl -X POST "http://localhost:7860/synthesize" \
     -F "text=Hello World"
```

## üîß Configuration

### ChatterboxTTS Parameters
- **`exaggeration`**: 0.25-2.0 (0.5 = neutral, higher = more expressive)
- **`temperature`**: 0.05-5.0 (controls randomness)
- **`cfg_weight`**: 0.0-1.0 (classifier-free guidance)
- **`min_p`**: 0.0-1.0 (minimum probability threshold)
- **`top_p`**: 0.0-1.0 (nucleus sampling)
- **`repetition_penalty`**: 1.0-2.0 (prevents repetition)

### Environment Variables
```bash
CUDA_VISIBLE_DEVICES=0    # GPU selection
PORT=7860                 # FastAPI port
GRADIO_PORT=7861         # Gradio port
```

## üìÅ Project Structure

```
chatterbox-whisper/
‚îú‚îÄ‚îÄ app.py                    # Main FastAPI + Gradio application
‚îú‚îÄ‚îÄ chatterbox_demo.py        # ChatterboxTTS integration
‚îú‚îÄ‚îÄ whisper_demo.py           # Faster-Whisper integration
‚îú‚îÄ‚îÄ gradio_tts_app.py         # Standalone TTS Gradio app
‚îú‚îÄ‚îÄ voice_conversion_app.py   # Standalone VC Gradio app
‚îú‚îÄ‚îÄ Dockerfile               # Production Docker image
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îî‚îÄ‚îÄ README.md               # This file
```

## üéõÔ∏è Gradio Interface Features

### üéß Transcribe Audio Tab
- Upload audio files or record via microphone
- Real-time transcription using Faster-Whisper
- Copy-to-clipboard functionality

### üó£Ô∏è Text-to-Speech Tab
- Multiple voice options
- Advanced ChatterboxTTS controls
- Real-time parameter adjustment
- Example texts for testing

### üé≠ Voice Cloning Tab
- Upload reference audio for voice cloning
- Custom voice naming
- High-quality voice replication

### üîÑ Voice Conversion Tab
- Convert existing audio to different voices
- Target voice selection via reference audio
- Batch processing support

### ‚öôÔ∏è Settings & Info Tab
- System status monitoring
- Available voices listing
- CUDA/GPU status
- Real-time diagnostics

## üöÄ Advanced Usage

### Custom Model Training
ChatterboxTTS supports custom model fine-tuning:

```python
# Example: Fine-tune on custom dataset
model = ChatterboxTTS.from_pretrained("cuda")
model.fine_tune(
    dataset_path="custom_dataset/",
    epochs=100,
    learning_rate=1e-4
)
```

### Batch Processing
```python
# Process multiple texts
texts = ["Hello", "World", "How are you?"]
for text in texts:
    wav = model.generate(text)
    # Save or process wav
```

### API Integration
```python
import requests

# Transcription API
with open("audio.wav", "rb") as f:
    response = requests.post(
        "http://localhost:7860/transcribe",
        files={"file": f}
    )
    print(response.json()["transcription"])

# TTS API
response = requests.post(
    "http://localhost:7860/synthesize",
    data={"text": "Hello World"}
)
with open("output.wav", "wb") as f:
    f.write(response.content)
```

## üî¨ Technical Details

### Model Architecture
- **ChatterboxTTS**: Transformer-based neural TTS with diffusion
- **ChatterboxVC**: Neural voice conversion with speaker encoding
- **Faster-Whisper**: Optimized Whisper implementation

### Performance Optimizations
- **CUDA acceleration** for GPU inference
- **Model caching** for faster startup
- **Streaming audio processing**
- **Batch inference** support

### Audio Formats
- **Input**: WAV, MP3, FLAC, OGG
- **Output**: WAV (16-bit, 22kHz default)
- **Quality**: Professional broadcast quality

## üõ†Ô∏è Development

### Local Development
```bash
# Clone repository
git clone <your-repo-url>
cd chatterbox-whisper

# Install dependencies
pip install -r requirements.txt

# Run development server
python app.py
```

### Testing
```bash
# Test TTS functionality
python test-tts.py

# Test individual components
python gradio_tts_app.py      # TTS only
python voice_conversion_app.py # VC only
```

## üö® Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   - Reduce batch size
   - Use CPU inference: `CUDA_VISIBLE_DEVICES=-1`

2. **Import Errors**
   - Verify chatterbox-tts installation: `pip install chatterbox-tts`
   - Check Python version (3.11 recommended)

3. **Audio Quality Issues**
   - Ensure input audio is high quality (>16kHz)
   - Check reference audio format for voice cloning

4. **Performance Issues**
   - Enable GPU acceleration
   - Increase system RAM
   - Use SSD storage

### Logs and Debugging
```bash
# View application logs
docker logs <container-id>

# Enable debug mode
export LOG_LEVEL=DEBUG
python app.py
```

## üìä Performance Benchmarks

| Operation | GPU (RTX 4090) | CPU (Intel i9) |
|-----------|----------------|-----------------|
| TTS (1 sentence) | ~0.5s | ~3s |
| Voice Cloning | ~1s | ~8s |
| Voice Conversion | ~0.8s | ~5s |
| Transcription (1 min audio) | ~2s | ~15s |

## ü§ù Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -am 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit pull request

## üìÑ License

This project uses ChatterboxTTS by Resemble AI. Please check the [ChatterboxTTS license](https://github.com/resemble-ai/chatterbox) for usage terms.

## üîó Links

- [ChatterboxTTS GitHub](https://github.com/resemble-ai/chatterbox)
- [Faster-Whisper](https://github.com/guillaumekln/faster-whisper)
- [Gradio Documentation](https://gradio.app/docs/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

---

**Built with ‚ù§Ô∏è using ChatterboxTTS, Faster-Whisper, and modern AI tools.**
